import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { streamObject } from 'ai';
import { z } from 'zod';
import { db } from '@/lib/db';
import { cachedResults } from '@/lib/db/schema';
import { eq } from 'drizzle-orm';
import { auth } from '@clerk/nextjs/server';

// üöÄ COST OPTIMIZATION: Use Google Gemini 2.5 Flash (FREE tier)
const google = createGoogleGenerativeAI({
  apiKey: process.env.GOOGLE_GENERATIVE_AI_API_KEY || '',
});

// üè• HEALTH CHECK: Test AI connection on server startup
let healthCheckPassed = false;
let healthCheckError: string | null = null;

async function performHealthCheck() {
  try {
    console.log('üè• Performing AI Health Check...');
    
    const testSchema = z.object({
      message: z.string(),
    });
    
    const testResult = streamObject({
      model: google('gemini-1.5-flash-latest'), // ‚úÖ FIXED: Use gemini-2.5-flash (latest available model)
      schema: testSchema,
      prompt: 'Reply with: "OK"',
    });
    
    // Actually consume the stream to catch errors
    const { object } = await testResult;
    const result = await object;
    
    if (result && result.message) {
      healthCheckPassed = true;
      console.log('‚úÖ AI Health Check PASSED - Gemini 2.5 Flash is working');
    } else {
      throw new Error('Health check returned invalid response');
    }
  } catch (error: unknown) {
    healthCheckPassed = false;
    healthCheckError = error instanceof Error ? error.message : 'Unknown error';
    console.error('‚ùå AI Health Check FAILED:', healthCheckError);
    console.error('‚ö†Ô∏è Please check:');
    console.error('   - GOOGLE_GENERATIVE_AI_API_KEY is set correctly in .env.local');
    console.error('   - API key has not exceeded quota or restrictions');
    console.error('   - Model name is correct (using gemini-2.5-flash)');
    if (error && typeof error === 'object' && 'statusCode' in error && error.statusCode === 404) {
      console.error('   - Model not found. Available models: gemini-2.5-flash, gemini-2.0-flash, gemini-flash-latest');
    }
  }
}

// Run health check on module load (server startup)
performHealthCheck();

// Cho ph√©p request ch·∫°y t·ªëi ƒëa 30s (tr√°nh b·ªã timeout)
export const maxDuration = 30;

// üß† BASE SCHEMA: Script + Viral Analysis (without visuals - saves tokens)
const baseScriptSchema = z.object({
  // Core Script Content
  hook: z.string().describe('C√¢u n√≥i m·ªü ƒë·∫ßu c·ª±c s·ªëc (0-3 gi√¢y) - Ph·∫£i trigger c·∫£m x√∫c m·∫°nh'),
  script: z.string().describe('N·ªôi dung ch√≠nh c·ªßa video (3-20 gi√¢y), chia th√†nh c√°c g·∫°ch ƒë·∫ßu d√≤ng ng·∫Øn g·ªçn'),
  cta: z.string().describe('C√¢u k√™u g·ªçi h√†nh ƒë·ªông cu·ªëi video - Khuy·∫øn kh√≠ch t∆∞∆°ng t√°c'),
  
  // üî• Viral Analysis Layer
  analysis: z.object({
    hookPsychology: z.string().describe('Gi·∫£i th√≠ch T·∫†I SAO hook n√†y hi·ªáu qu·∫£ - T·ªëi ƒëa 15 t·ª´'),
    viralScore: z.number().min(1).max(10).describe('ƒêi·ªÉm viral t·ª´ 1-10'),
    audienceInsight: z.string().describe('ƒê·ªëi t∆∞·ª£ng m·ª•c ti√™u c·ª• th·ªÉ'),
    viralFramework: z.string().describe('Framework ƒë√£ s·ª≠ d·ª•ng'),
  }),
});

// üé¨ FULL SCHEMA: With Visual Prompt (when includeVisuals = true)
const fullScriptSchema = baseScriptSchema.extend({
  visualPrompt: z.string().describe('Prompt ti·∫øng Anh t·ªëi ∆∞u cho Kling/Runway/Luma ƒë·ªÉ t·∫°o video AI. M√¥ t·∫£ chi ti·∫øt: subject, scene, camera movement, lighting, mood, color. VD: "Young Vietnamese woman in modern cafe, warm lighting, slow zoom in, cinematic color grading, 4k"'),
});

type BaseScriptResult = z.infer<typeof baseScriptSchema>;
type FullScriptResult = z.infer<typeof fullScriptSchema>;

export async function POST(req: Request) {
  const startTime = Date.now();
  
  // üîê Get userId from Clerk (null for guests, string for logged-in users)
  const { userId } = await auth();
  const isGuest = !userId;
  console.log(`üë§ User status: ${isGuest ? 'Guest' : `Logged in (${userId})`}`);
  
  try {
    // Check if health check failed
    if (!healthCheckPassed && healthCheckError) {
      console.error('‚ö†Ô∏è Rejecting request - Health check failed on startup');
      return new Response(
        JSON.stringify({ 
          error: 'AI service is unavailable',
          details: healthCheckError,
          suggestion: 'Check server logs and verify GOOGLE_GENERATIVE_AI_API_KEY',
        }),
        { status: 503, headers: { 'Content-Type': 'application/json' } }
      );
    }

    const body = await req.json();
    const { topic, vibe, platform, includeVisuals = false } = body;

    console.log('üì• API received:', { topic, vibe, platform, includeVisuals, isGuest });

    // Validate input
    if (!topic || !vibe || !platform) {
      return new Response(
        JSON.stringify({ error: 'Missing required fields: topic, vibe, platform' }),
        { status: 400, headers: { 'Content-Type': 'application/json' } }
      );
    }

    // üîë STEP A: Create normalized cache key (include visuals flag)
    const cacheKey = `${topic.toLowerCase().trim()}-${vibe}-${platform}-v${includeVisuals ? '1' : '0'}`;
    console.log('üîç Cache key:', cacheKey);

    // üîç STEP B: Check database cache (non-blocking on error)
    try {
      const cached = await db
        .select()
        .from(cachedResults)
        .where(eq(cachedResults.cacheKey, cacheKey))
        .limit(1);

      if (cached.length > 0) {
        const elapsedTime = Date.now() - startTime;
        console.log(`‚úÖ CACHE HIT - Returning cached result (${elapsedTime}ms)`);
        
        const cachedData = cached[0].data as BaseScriptResult | FullScriptResult;

        // ‚úÖ FIXED: Return raw JSON text stream (same as streamObject.toTextStreamResponse)
        // experimental_useObject expects progressive JSON text chunks, not prefixed format
        const jsonStr = JSON.stringify(cachedData, null, 2);
        const encoder = new TextEncoder();
        
        // Stream the JSON in chunks to simulate progressive loading
        const stream = new ReadableStream({
          async start(controller) {
            // Split JSON into chunks and stream progressively
            const chunkSize = 50;
            for (let i = 0; i < jsonStr.length; i += chunkSize) {
              const chunk = jsonStr.slice(i, i + chunkSize);
              controller.enqueue(encoder.encode(chunk));
              await new Promise(r => setTimeout(r, 10)); // Small delay for UX
            }
            controller.close();
          },
        });

        return new Response(stream, {
          headers: {
            'Content-Type': 'text/plain; charset=utf-8',
            'X-Cache-Status': 'HIT',
            'X-Model': 'gemini-2.5-flash',
            'X-Response-Time': `${elapsedTime}ms`,
          },
        });
      }

      console.log('‚ùå CACHE MISS - Calling Gemini API');
    } catch (dbError) {
      console.error('‚ö†Ô∏è Database cache check failed:', dbError);
      // Continue to API call - caching is not critical
    }

    // ü§ñ STEP C: Call Google Gemini API with Director Mode Prompt
    // Choose schema based on includeVisuals flag
    const activeSchema = includeVisuals ? fullScriptSchema : baseScriptSchema;
    console.log(`üöÄ Calling Gemini 2.5 Flash (includeVisuals: ${includeVisuals})...`);
    
    // Build visual instruction if needed
    const visualInstruction = includeVisuals ? `
5. VISUAL PROMPT (Ti·∫øng Anh - cho AI Video Tools):
   - M√¥ t·∫£ chi ti·∫øt scene b·∫±ng ti·∫øng Anh
   - Bao g·ªìm: subject, environment, camera movement, lighting, mood, color palette
   - T·ªëi ∆∞u cho Kling AI, Runway, Luma
   - VD: "Young Vietnamese entrepreneur in modern coffee shop, golden hour lighting, slow dolly in, warm color grading, cinematic 4k, shallow depth of field"
` : '';
    
    const result = streamObject({
      model: google('gemini-2.5-flash'),
      schema: activeSchema,
      prompt: `
B·∫°n l√† "Viral Short Architect" - Ki·∫øn tr√∫c s∆∞ N·ªôi dung Viral chuy√™n nghi·ªáp.
B·∫°n hi·ªÉu s√¢u v·ªÅ thu·∫≠t to√°n TikTok/Reels/Shorts v√† t√¢m l√Ω ng∆∞·ªùi xem Vi·ªát Nam.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üéØ INPUT T·ª™ USER:
- Ch·ªß ƒë·ªÅ: "${topic}"
- Phong c√°ch: ${vibe}
- N·ªÅn t·∫£ng: ${platform}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üß† QUY TR√åNH SUY LU·∫¨N (Chain-of-Thought):

1. PH√ÇN T√çCH: X√°c ƒë·ªãnh pain point/desire c·ªët l√µi c·ªßa ch·ªß ƒë·ªÅ
2. CH·ªåN FRAMEWORK: Polarization, Negative Hook, Transformation, Curiosity Gap, ho·∫∑c Social Proof
3. T·∫†O HOOK: Trigger c·∫£m x√∫c m·∫°nh (B·∫•t ng·ªù, S·ª£ h√£i, Tham lam, H√†i h∆∞·ªõc, T·ª©c gi·∫≠n, T√≤ m√≤)
4. T·ª∞ ƒê√ÅNH GI√Å: Ch·∫•m ƒëi·ªÉm viral 1-10

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìã Y√äU C·∫¶U OUTPUT:

1. HOOK (0-3 gi√¢y): C·ª±c ng·∫Øn, ƒë√°nh th·∫≥ng v√†o c·∫£m x√∫c, ng√¥n ng·ªØ Gen Z t·ª± nhi√™n

2. SCRIPT (3-20 gi√¢y): 3-4 bullet points ng·∫Øn g·ªçn, pace nhanh

3. CTA: K√™u g·ªçi h√†nh ƒë·ªông c·ª• th·ªÉ, t·∫°o FOMO/urgency

4. ANALYSIS:
   - hookPsychology: T·∫°i sao hook hi·ªáu qu·∫£ (t·ªëi ƒëa 15 t·ª´)
   - viralScore: ƒêi·ªÉm 1-10
   - audienceInsight: ƒê·ªëi t∆∞·ª£ng c·ª• th·ªÉ
   - viralFramework: Framework ƒë√£ d√πng
${visualInstruction}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
‚ö° B·∫ÆT ƒê·∫¶U T·∫†O NGAY:
      `.trim(),
      
      // üíæ STEP D: Save to cache when generation completes (only for logged-in users)
      onFinish: async ({ object, error }) => {
        if (error) {
          console.error('‚ùå Generation error:', error);
          return;
        }

        if (!object) {
          console.warn('‚ö†Ô∏è No object returned from Gemini');
          return;
        }

        const elapsedTime = Date.now() - startTime;
        console.log(`‚ú® Generation completed (${elapsedTime}ms)`);

        // üîê Only save to database for logged-in users
        if (isGuest) {
          console.log('üëª Guest user - skipping cache save (no persistent storage)');
          return;
        }

        // Save to database cache (non-blocking - don't fail request if this fails)
        try {
          await db.insert(cachedResults).values({
            cacheKey,
            data: object as BaseScriptResult | FullScriptResult,
          });
          console.log('üíæ Saved to cache:', cacheKey);
        } catch (saveError) {
          console.error('‚ö†Ô∏è Failed to save to cache (non-critical):', saveError);
          // Don't throw - caching failure shouldn't break the response
        }
      },
    });

    // Return the streaming response
    const response = result.toTextStreamResponse();
    
    // Add custom headers
    const headers = new Headers(response.headers);
    headers.set('X-Cache-Status', 'MISS');
    headers.set('X-Model', 'gemini-2.5-flash'); // ‚úÖ FIXED: Updated to gemini-2.5-flash
    
    return new Response(response.body, {
      status: response.status,
      statusText: response.statusText,
      headers,
    });

  } catch (error) {
    console.error('üí• API Error:', error);
    
    return new Response(
      JSON.stringify({ 
        error: 'Failed to generate content',
        message: error instanceof Error ? error.message : 'Unknown error',
      }),
      { 
        status: 500, 
        headers: { 'Content-Type': 'application/json' },
      }
    );
  }
}
